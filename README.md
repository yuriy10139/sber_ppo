# Решение задачи Inverted Pendulum с помощью алогоритма PPO
Решение классической задачи установки маятника в вертикальное положение приложением усилий к подвижной базе, на которой он закреплен. 
В решении использована реализация алгоритма PPO CleanRL: https://github.com/vwxyzjn/cleanrl 

## Установка
Удобнее устанавливать зависимости в виртуальное окружение:
```
python3 -m venv ppo_venv
source ppo_venv/bin/activate

git clone https://github.com/yuriy10139/sber_ppo.git
python3 -m pip install -r requirements.txt
```

Для записи видео экспериментов необходимо установить ffmpeg. Пример команды установки для Ubuntu:

```
sudo apt update
sudo apt install ffmpeg
```

## Обучение
Обучение агента возможно в двух вариантах. В простом варианте агент учится уравновешивать маятник в вертикальном положении в произвольной позиции базы. 
Пример команды запуска обучения в четырех параллельных окружениях с записью видео с шага 50000:
```
python3 ppo_cont_action.py --seed=3 --capture-video --record-video-from=50000 --learning-rate=0.0012 --num-envs=4
```

В сложном варианте агент учится балансировать маятник в определенной точке. Пример команды:
```
python3 ppo_cont_action.py --seed=3 --capture-video --record-video-from=50000 --learning-rate=0.0012 --num-envs=4 --set-target --set-target-step=70000
```
Параметр --set-target указывает, что обучение необходимо провести по сложному сценарию. 
Параметр --set-target-step указывает, начиная с какого шага необходимо создавать цель в окружении (для поэтапного обучения)

## Запуск экспериментов на сохраненых весах
Сохраненные в процессе обучения веса можно протестировать с помощью скрипта evaluate.py
```
python3 evaluate.py --model-path=runs/InvertedPendulumEnv-v0__ppo_cont_action__3__1710937470/ppo_cont_action.cleanrl_model --set-target
```
В качестве параметров указывается путь к весам. Если обучение проводилось по сложному сценарию, в параметрах необходимо указать --set-target, в противном случае размерность
пространства состояний агента и сохраненных весов не совпадут.

При отсутствии параметра --set-x-coordinate цель будет создаваться в случайной точке в каждом эксперименте, количество которых определяется параметром --num-runs.
Если параметр --set-x-coordinate установлен, цель будет выставлена на интервале [-1.0, 1.0] в каждом эксперименте.

## Результаты экспериментов
Логи в формате tensorboard, веса модели и видео экспериментов сохраняются в папку ./runs/
